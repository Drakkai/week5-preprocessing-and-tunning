{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ML-Challenge/week5-preprocessing-and-tunning/blob/master/L2.Hyperparameter%20Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building powerful machine learning models depends heavily on the set of hyperparameters used. But with increasingly complex models with lots of options, how do we efficiently find the best settings for our particular problem? In this lesson we will get practical experience in using some common methodologies for automated hyperparameter tuning in Python using Scikit Learn. These include Grid Search, Random Search & advanced optimization methodologies including Bayesian & Genetic algorithms. We will use a dataset predicting credit card defaults as we build skills to dramatically increase the efficiency and effectiveness of our machine learning model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:26.585604Z",
     "start_time": "2020-02-19T18:49:26.571604Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Download lesson datasets\n",
    "# Required if you're using Google Colab\n",
    "#!wget \"https://github.com/ML-Challenge/week5-preprocessing-and-tunning/raw/master/datasets.zip\"\n",
    "#!unzip -o datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.179977Z",
     "start_time": "2020-02-19T18:49:26.587602Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import utils\n",
    "# We'll be using this module throughout the lesson\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.837220Z",
     "start_time": "2020-02-19T18:49:27.182969Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# and setting the size of all plots.\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this introductory section, we will learn the difference between hyperparameters and parameters. We will practice extracting and analyzing parameters, setting hyperparameter values for several popular machine learning algorithms. Along the way we will learn some best practice tips & tricks for choosing which hyperparameters to tune and what values to set & build learning curves to analyze our hyperparameter choices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction & 'Parameters'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters in Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have had a chance to explore what a parameter is, let us apply this knowledge. It is important to be able to review any new algorithm and identify which elements are parameters and hyperparameters.\n",
    "\n",
    "Which of the following is a parameter for the Scikit Learn logistic regression model?\n",
    "\n",
    "**Possible Answers**\n",
    "\n",
    "1. `n_jobs`\n",
    "2. `coef_`\n",
    "3. `class_weight`\n",
    "4. `LogisticRegression()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.853179Z",
     "start_time": "2020-02-19T18:49:27.840210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pass 1,2,3 or 4 as argument\n",
    "utils.which_is_param()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Logistic Regression parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to practice extracting an important parameter of the logistic regression model. The logistic regression has a few other parameters we will not explore here, but they can be reviewed in the **scikit-learn.org** documentation for the `LogisticRegression()` module under 'Attributes'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This parameter is important for understanding the direction and magnitude of the effect the variables have on the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will extract the coefficient parameter (found in the `coef_` attribute), zip it up with the original column names, and see which variables had the largest positive effect on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.884094Z",
     "start_time": "2020-02-19T18:49:27.857165Z"
    }
   },
   "outputs": [],
   "source": [
    "utils.credit_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.915035Z",
     "start_time": "2020-02-19T18:49:27.890078Z"
    }
   },
   "outputs": [],
   "source": [
    "X = utils.credit_card.drop('default payment next month', axis=1)\n",
    "y = utils.credit_card['default payment next month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.946924Z",
     "start_time": "2020-02-19T18:49:27.918004Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:27.977843Z",
     "start_time": "2020-02-19T18:49:27.949916Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.023720Z",
     "start_time": "2020-02-19T18:49:27.979839Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg_clf = LogisticRegression(solver='liblinear', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.818596Z",
     "start_time": "2020-02-19T18:49:28.025714Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.834552Z",
     "start_time": "2020-02-19T18:49:28.820590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of original variable names from the training DataFrame\n",
    "original_variables = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.850509Z",
     "start_time": "2020-02-19T18:49:28.837543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the coefficients of the logistic regression estimator\n",
    "model_coefficients = log_reg_clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.881426Z",
     "start_time": "2020-02-19T18:49:28.853500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe of the variables and coefficients & print it out\n",
    "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
    "coefficient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.896416Z",
     "start_time": "2020-02-19T18:49:28.883420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print out the top 3 positive variables\n",
    "top_three_df = coefficient_df.sort_values(by=\"Coefficient\", axis=0, ascending=False)[0:3]\n",
    "top_three_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have succesfully extracted and reviewed a very important parameter for the Logistic Regression Model. The coefficients of the model allow us to see which variables are having a larger or smaller impact on the outcome. Additionally the sign lets us know if it is a positive or negative relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting a Random Forest parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now translate the work previously undertaken on the logistic regression model to a random forest model. A parameter of this model is, for a given tree, how it decided to split at each level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis is not as useful as the coefficients of logistic regression as we will be unlikely to ever explore every split and every tree in a random forest model. However, it is a very useful exercise to peak under the hood at what the model is doing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will extract a single tree from our random forest model, visualize it and programmatically extract one of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:28.972183Z",
     "start_time": "2020-02-19T18:49:28.899380Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(max_depth=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:30.448269Z",
     "start_time": "2020-02-19T18:49:28.976175Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:30.464227Z",
     "start_time": "2020-02-19T18:49:30.450264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the 7th (index 6) tree from the random forest\n",
    "chosen_tree = rf_clf.estimators_[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:30.480184Z",
     "start_time": "2020-02-19T18:49:30.467219Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the graph using Graphviz\n",
    "\n",
    "#from sklearn.tree import export_graphviz\n",
    "\n",
    "#export_graphviz(chosen_tree, out_file='assets/tree.dot', \n",
    "#                feature_names = original_variables, class_names = True,\n",
    "#                rounded = True, proportion = False, precision = 2, filled = True)\n",
    "\n",
    "# Convert to png using system command \n",
    "#from subprocess import call\n",
    "#call(['dot', '-Tpng', 'assets/tree.dot', '-o', 'assets/tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "#from IPython.display import Image\n",
    "#Image(filename = 'assets/tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:31.385452Z",
     "start_time": "2020-02-19T18:49:30.482179Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plot_tree(chosen_tree,feature_names = original_variables, class_names = True,\n",
    "                rounded = True, proportion = False, precision = 2, filled = True, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters in Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, there are many different hyperparameters available in a Random Forest model using Scikit Learn. Let's try to differentiate between a hyperparameter and a parameter, and easily check whether something is a hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a random forest estimator from the imported Scikit Learn package. Then print this estimator out to see the hyperparameters and their values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-17T09:33:20.376425Z",
     "start_time": "2020-02-17T09:33:20.366452Z"
    }
   },
   "source": [
    "Which of the following is a hyperparameter for the Scikit Learn random forest model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:31.400412Z",
     "start_time": "2020-02-19T18:49:31.387446Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Answers**\n",
    "\n",
    "1. `oob_score`\n",
    "2. `classes_`\n",
    "3. `trees`\n",
    "4. `random_level`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:31.416390Z",
     "start_time": "2020-02-19T18:49:31.402409Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pass 1,2,3 or 4 as argument\n",
    "utils.which_is_hyperparam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Random Forest Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding what hyperparameters are available and the impact of different hyperparameters is a core skill for any data scientist. As models become more complex, there are many different settings we can set, but only some will have a large impact on our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now assess an existing random forest model (it has some bad choices for hyperparameters!) and then make better choices for a new random forest model and assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:31.696129Z",
     "start_time": "2020-02-19T18:49:31.420359Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_clf_bad = RandomForestClassifier(n_estimators=5, random_state=42)\n",
    "rf_clf_bad.fit(X_train, y_train)\n",
    "rf_bad_predictions = rf_clf_bad.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:31.726048Z",
     "start_time": "2020-02-19T18:49:31.701140Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Get confusion matrix & accuracy for the bad rf_model\n",
    "print(f'Confusion Matrix: \\n\\n {confusion_matrix(y_test, rf_bad_predictions)} \\n Accuracy Score: \\n\\n {accuracy_score(y_test, rf_bad_predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:31.742007Z",
     "start_time": "2020-02-19T18:49:31.728043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new random forest classifier with better hyperparamaters\n",
    "rf_clf_new = RandomForestClassifier(n_estimators=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:57.119753Z",
     "start_time": "2020-02-19T18:49:31.744000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit this to the data and obtain predictions\n",
    "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:57.135713Z",
     "start_time": "2020-02-19T18:49:57.121747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get confusion matrix & accuracy for the new rf_model\n",
    "print(f'Confusion Matrix: \\n\\n {confusion_matrix(y_test, rf_new_predictions)} \\n Accuracy Score: \\n\\n {accuracy_score(y_test, rf_new_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a nice 3% accuracy boost just from changing the `n_estimators`. We have had our first taste of hyperparameter tuning for a random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters of KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-nearest-neighbors algorithm is not as popular as it used to be, but can still be an excellent choice for data that has groups of data that behave similarly. Could this be the case for our credit card users?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we will try out several different values for one of the core hyperparameters for the knn algorithm and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:49:57.151671Z",
     "start_time": "2020-02-19T18:49:57.137707Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Build a knn estimator for each value of n_neighbours\n",
    "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
    "knn_20 = KNeighborsClassifier(n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:01.810208Z",
     "start_time": "2020-02-19T18:49:57.154661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit each to the training data & produce predictions\n",
    "knn_5_predictions = knn_5.fit(X_train, y_train).predict(X_test)\n",
    "knn_10_predictions = knn_10.fit(X_train, y_train).predict(X_test)\n",
    "knn_20_predictions = knn_20.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:01.825171Z",
     "start_time": "2020-02-19T18:50:01.812203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get an accuracy score for each of the models\n",
    "knn_5_accuracy = accuracy_score(y_test, knn_5_predictions)\n",
    "knn_10_accuracy = accuracy_score(y_test, knn_10_predictions)\n",
    "knn_20_accuracy = accuracy_score(y_test, knn_20_predictions)\n",
    "\n",
    "print(f\"The accuracy of 5, 10, 20 neighbours was {knn_5_accuracy}, {knn_10_accuracy}, {knn_20_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We succesfully tested 3 different options for 1 hyperparameter, but it was pretty exhausting. Next, we will try to find a way to make this easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting & Analyzing Hyperparameter Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating Hyperparameter Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best hyperparameter of interest without writing hundreds of lines of code for hundreds of models is an important efficiency gain that will greatly assist our future machine learning model building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important hyperparameter for the GBM algorithm is the learning rate. But which learning rate is best for this problem? By writing a loop to search through a number of possibilities, collating these and viewing them we can find the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible learning rates to try include 0.001, 0.01, 0.05, 0.1, 0.2 and 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:01.840130Z",
     "start_time": "2020-02-19T18:50:01.829157Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:01.855089Z",
     "start_time": "2020-02-19T18:50:01.842125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the learning rates & results storage\n",
    "learning_rates = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "results_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:43.360578Z",
     "start_time": "2020-02-19T18:50:01.858082Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the for loop to evaluate model predictions for each learning rate\n",
    "for learning_rate in learning_rates:\n",
    "    model = GradientBoostingClassifier(learning_rate=learning_rate, random_state=42)\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    # Save the learning rate and accuracy score\n",
    "    results_list.append([learning_rate, accuracy_score(y_test, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:43.375538Z",
     "start_time": "2020-02-19T18:50:43.362573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gather everything into a DataFrame\n",
    "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We efficiently tested a few different values for a single hyperparameter and can easily see which learning rate value was the best. Here, it seems that a learning rate of 0.05 yields the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Learning Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to test many different values for a single hyperparameter it can be difficult to easily view that in the form of a DataFrame. Previously we learned about a nice trick to analyze this. A graph called a 'learning curve' can nicely demonstrate the effect of increasing or decreasing a particular hyperparameter on the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of testing only a few values for the learning rate, we will test many to easily see the effect of this hyperparameter across a large range of values. A useful function from NumPy is `np.linspace(start, end, num)` which allows us to create a number of values (`num`) evenly spread within an interval (`start`, `end`) that we specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:50:43.391495Z",
     "start_time": "2020-02-19T18:50:43.379528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the learning rates & accuracies list\n",
    "learn_rates = np.linspace(0.01, 2, num=30)\n",
    "accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:54:05.080909Z",
     "start_time": "2020-02-19T18:50:43.394487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the for loop\n",
    "for learn_rate in learn_rates:\n",
    "    # Create the model, predictions & save the accuracies as before\n",
    "    model = GradientBoostingClassifier(learning_rate=learn_rate, random_state=42)\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    accuracies.append(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:54:05.328196Z",
     "start_time": "2020-02-19T18:54:05.082850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results    \n",
    "plt.plot(learn_rates, accuracies)\n",
    "plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that for low values, we get a pretty good accuracy. However once the learning rate pushes much above 1.5, the accuracy starts to drop. We have learned and practiced a useful skill for visualizing large amounts of results for a single hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the lesson introduces a popular automated hyperparameter tuning methodology called Grid Search. We will learn what it is, how it works and practice undertaking a Grid Search using Scikit Learn. We will then learn how to analyze the output of a Grid Search & gain practical experience doing this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Grid Search functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In data science it is a great idea to try building algorithms, models and processes 'from scratch' so we can really understand what is happening at a deeper level. Of course there are great packages and libraries for this work (and we will get to that very soon!) but building from scratch will give us a great edge in our data science work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will create a function to take in 2 hyperparameters, build models and return results. We will use this function in a future example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:54:05.343154Z",
     "start_time": "2020-02-19T18:54:05.330189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the function\n",
    "def gbm_grid_search(learn_rate, max_depth, random_state=42):\n",
    "\n",
    "    # Create the model\n",
    "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, random_state=random_state)\n",
    "    \n",
    "    # Use the model to make predictions\n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Return the hyperparameters and score\n",
    "    return([learn_rate, max_depth, accuracy_score(y_test, predictions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteratively tune multiple hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will build on the function we previously created to take in 2 hyperparameters, build a model and return the results. We will now use that to loop through some values and then extend this function and loop with another hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:54:05.358113Z",
     "start_time": "2020-02-19T18:54:05.344151Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the relevant lists\n",
    "results_list = []\n",
    "learn_rate_list = [0.01, 0.1, 0.5]\n",
    "max_depth_list = [2,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:55:25.042572Z",
     "start_time": "2020-02-19T18:54:05.360108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the for loop\n",
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        results_list.append(gbm_grid_search(learn_rate,max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:55:25.058530Z",
     "start_time": "2020-02-19T18:55:25.044567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the results\n",
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:55:25.074519Z",
     "start_time": "2020-02-19T18:55:25.062520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extend the function input\n",
    "def gbm_grid_search_extended(learn_rate, max_depth, subsample, random_state=42):\n",
    "\n",
    "    # Extend the model creation section\n",
    "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, subsample=subsample, random_state=42)\n",
    "    \n",
    "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    # Extend the return part\n",
    "    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:55:25.090444Z",
     "start_time": "2020-02-19T18:55:25.078477Z"
    }
   },
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "# Create the new list to test\n",
    "subsample_list = [0.4, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.075867Z",
     "start_time": "2020-02-19T18:55:25.092467Z"
    }
   },
   "outputs": [],
   "source": [
    "for learn_rate in learn_rate_list:\n",
    "    for max_depth in max_depth_list:\n",
    "        # Extend the for loop\n",
    "        for subsample in subsample_list:\n",
    "            # Extend the results to include the new hyperparameter\n",
    "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.091085Z",
     "start_time": "2020-02-19T18:56:51.078159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print results\n",
    "results_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have effectively built our own grid search! We went from 2 to 3 hyperparameters and can see how we could extend that to even more values and hyperparameters. That was a lot of effort though. Be warned - we are now entering a world that can get very computationally expensive very fast!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more hyperparameters or values, we increase the amount of models created but the increase is not linear, it is proportional to how many values and hyperparameters we already have.\n",
    "\n",
    "How many models would be created when running a grid search over the following hyperparameters and values for a GBM algorithm?\n",
    "\n",
    "* learning_rate = [0.001, 0.01, 0.05, 0.1, 0.2, 0.3, 0.5, 1, 2]\n",
    "* max_depth = [4,6,8,10,12,14,16,18, 20]\n",
    "* subsample = [0.4, 0.6, 0.7, 0.8, 0.9]\n",
    "* max_features = ['auto', 'sqrt', 'log2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Answers**\n",
    "\n",
    "1. 26\n",
    "2. 9 of one model, 9 of another\n",
    "3. 1 large model\n",
    "4. 1215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.107041Z",
     "start_time": "2020-02-19T18:56:51.094075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enter 1, 2, 3 or 4 as the answer\n",
    "utils.how_many_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our knowledge of GridSeachCV inputs by answering the question below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three GridSearchCV objects are available below. Note that there is no data available to fit these models. Instead, answer by looking at their construct.\n",
    "\n",
    "```\n",
    "Model #1:\n",
    " GridSearchCV(cv=5, error_score='raise-deprecating',\n",
    "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
    "            oob_score=False, random_state=None, verbose=0,\n",
    "            warm_start=False),\n",
    "       fit_params=None, iid='warn', n_jobs=4,\n",
    "       param_grid={'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
    "       scoring='roc_auc', verbose=0) \n",
    "\n",
    "\n",
    "Model #2:\n",
    " GridSearchCV(cv=10, error_score='raise-deprecating',\n",
    "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
    "           weights='uniform'),\n",
    "       fit_params=None, iid='warn', n_jobs=8,\n",
    "       param_grid={'n_neighbors': [5, 10, 20], 'algorithm': ['ball_tree', 'brute']},\n",
    "       pre_dispatch='2*n_jobs', refit=False, return_train_score='warn',\n",
    "       scoring='accuracy', verbose=0) \n",
    "\n",
    "\n",
    "Model #3:\n",
    " GridSearchCV(cv=7, error_score='raise-deprecating',\n",
    "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
    "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
    "              max_features=None, max_leaf_nodes=None,\n",
    "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
    "              verbose=0, warm_start=False),\n",
    "       fit_params=None, iid='warn', n_jobs=2,\n",
    "       param_grid={'number_attempts': [2, 4, 6], 'max_depth': [3, 6, 9, 12]},\n",
    "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
    "       scoring='accuracy', verbose=0)\n",
    "```\n",
    "\n",
    "Which of these GridSearchCV objects would not work when we try to fit it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Possible Answers**\n",
    "\n",
    "1. `Model #1` would not work when we try to fit it.\n",
    "2. `Model #2` would not work when we try to fit it.\n",
    "3. `Model #3` would not work when we try to fit it.\n",
    "4. None - they will all work when we try to fit them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.122001Z",
     "start_time": "2020-02-19T18:56:51.111028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enter 1, 2, 3 or 4 as the answer\n",
    "utils.which_grid_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV with Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `GridSearchCV` module from Scikit Learn provides many useful features to assist with efficiently undertaking a grid search. We will now put it into practice by creating a GridSearchCV object with certain parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired options are:\n",
    "\n",
    "* A Random Forest Estimator, with the split criterion as 'entropy'\n",
    "* 5-fold cross validation\n",
    "* The hyperparameters `max_depth` (2, 4, 8, 15) and `max_features` ('auto' vs 'sqrt')\n",
    "* Use `roc_auc` to score the models\n",
    "* Use 4 cores for processing in parallel\n",
    "* Ensure we refit the best model and return training scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.137957Z",
     "start_time": "2020-02-19T18:56:51.123995Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a Random Forest Classifier with specified criterion\n",
    "rf_class = RandomForestClassifier(criterion='entropy', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.153913Z",
     "start_time": "2020-02-19T18:56:51.139953Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:56:51.169873Z",
     "start_time": "2020-02-19T18:56:51.156919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a GridSearchCV object\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_rf_class=GridSearchCV(\n",
    "    estimator=rf_class,\n",
    "    param_grid=param_grid,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4,\n",
    "    cv=5,\n",
    "    refit=True, \n",
    "    return_train_score=True)\n",
    "\n",
    "grid_rf_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding a grid search output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the grid search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore the `cv_results_` property of the GridSearchCV object defined above. This is a dictionary that we can read into a pandas DataFrame and contains a lot of useful information about the grid search we just undertook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reminder of the different column types in this property:\n",
    "\n",
    "* `time_` columns\n",
    "* `param_` columns (one for each hyperparameter) and **the** singular `params` column (with all hyperparameter settings)\n",
    "* a `train_score` column for each cv fold including the `mean_train_score` and `std_train_score` columns\n",
    "* a `test_score` column for each cv fold including the `mean_test_score` and `std_test_score` columns\n",
    "* a `rank_test_score` column with a number from 1 to n (number of iterations) ranking the rows based on their `mean_test_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.514811Z",
     "start_time": "2020-02-19T18:56:51.172862Z"
    }
   },
   "outputs": [],
   "source": [
    "# First fit the GridSearchCV\n",
    "grid_rf_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.560682Z",
     "start_time": "2020-02-19T18:57:24.516773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the cv_results property into a dataframe & print it out\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.591606Z",
     "start_time": "2020-02-19T18:57:24.564647Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract and print the column with a dictionary of hyperparameters used\n",
    "column = cv_results_df.loc[:, [\"params\"]]\n",
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.623487Z",
     "start_time": "2020-02-19T18:57:24.593569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract and print the row that had the best mean test score\n",
    "best_row = cv_results_df[cv_results_df[\"rank_test_score\"] == 1]\n",
    "best_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the day, we primarily care about the best performing 'square' in a grid search. Luckily Scikit Learn's `gridSearchCV` objects have a number of parameters that provide key information on just the best square (or row in `cv_results_`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three properties we will explore are:\n",
    "\n",
    "* `best_score_` – The score (here ROC_AUC) from the best-performing square.\n",
    "* `best_index_` – The index of the row in `cv_results_` containing information on the best-performing square.\n",
    "* `best_params_` – A dictionary of the parameters that gave the best score, for example `'max_depth': 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.638448Z",
     "start_time": "2020-02-19T18:57:24.625504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print out the ROC_AUC score from the best-performing square\n",
    "best_score = grid_rf_class.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.668368Z",
     "start_time": "2020-02-19T18:57:24.641452Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable from the row related to the best-performing square\n",
    "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
    "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
    "best_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.683353Z",
     "start_time": "2020-02-19T18:57:24.670384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the max_depth parameter from the best-performing square\n",
    "best_max_depth = grid_rf_class.best_params_[\"max_depth\"]\n",
    "best_max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being able to quickly find and prioritize the huge volume of information given back from machine learning modeling output is a great skill. Here we had great practice doing that with `cv_results_` by quickly isolating the key information on the best performing square. This will be very important when our grids grow from 12 squares to many more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is interesting to analyze the results of our grid search, our final goal is practical in nature; we want to make predictions on our test set using our estimator object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access this object through the `best_estimator_` property of our grid search object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will take a look inside the `best_estimator_` property and then use this to make predictions on our test set for credit card defaults and generate a variety of scores. Remember that we need to use `predict_proba` rather than `predict` since we need probability values rather than class labels for our roc_auc score. We use a slice `[:,1]` to get probabilities of the positive class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.698289Z",
     "start_time": "2020-02-19T18:57:24.686352Z"
    }
   },
   "outputs": [],
   "source": [
    "# See what type of object the best_estimator_ property is\n",
    "type(grid_rf_class.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.808031Z",
     "start_time": "2020-02-19T18:57:24.700283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an array of predictions directly using the best_estimator_ property\n",
    "predictions = grid_rf_class.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.822979Z",
     "start_time": "2020-02-19T18:57:24.809989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
    "predictions[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.838913Z",
     "start_time": "2020-02-19T18:57:24.824950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now create a confusion matrix \n",
    "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.948661Z",
     "start_time": "2020-02-19T18:57:24.839944Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Get the ROC-AUC score\n",
    "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
    "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.best_estimator_` property is a really powerful property to understand for streamlining our machine learning model building process. We now can run a grid search and seamlessly use the best model from that search to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular automated hyperparameter tuning methodology is called Random Search. We will learn what it is, how it works and importantly how it differs from grid search. We will learn some advantages and disadvantages of this method and when to choose this method compared to Grid Search. We will practice undertaking a Random Search with Scikit Learn as well as visualizing & interpreting the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Sample Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To undertake a random search, we firstly need to undertake a random sampling of our hyperparameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will firstly create some lists of hyperparameters that can be zipped up to a list of lists. Then we will randomly sample hyperparameter combinations preparation for running a random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use just the hyperparameters `learning_rate` and `min_samples_leaf` of the GBM algorithm to keep the example illustrative and not overly complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.964575Z",
     "start_time": "2020-02-19T18:57:24.950612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of values for the learning_rate hyperparameter\n",
    "learn_rate_list = list(np.linspace(0.01,1.5,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.980533Z",
     "start_time": "2020-02-19T18:57:24.966575Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of values for the min_samples_leaf hyperparameter\n",
    "min_samples_list = list(range(10,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:24.996523Z",
     "start_time": "2020-02-19T18:57:24.982529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combination list\n",
    "from itertools import product\n",
    "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.012448Z",
     "start_time": "2020-02-19T18:57:24.998485Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample hyperparameter combinations for a random search.\n",
    "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
    "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.043365Z",
     "start_time": "2020-02-19T18:57:25.014443Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "combinations_random_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generated some hyperparameter combinations and randomly sampled in that space. The output was not too nice though, in the next example we will use a much more efficient method for this. In a future example we will also make this output look much nicer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Search with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solidify our knowledge of random sampling, let's try a similar exercise but using different hyperparameters and a different algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we create some lists of hyperparameters that can be zipped up to a list of lists. We will use the hyperparameters `criterion`, `max_depth` and `max_features` of the random forest algorithm. Then we will randomly sample hyperparameter combinations in preparation for running a random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a slightly different package for sampling in this task, `random.sample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.059347Z",
     "start_time": "2020-02-19T18:57:25.051367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create lists for criterion and max_features\n",
    "criterion_list = [\"gini\", \"entropy\"]\n",
    "max_feature_list = [\"auto\", \"sqrt\", \"log2\", None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.074281Z",
     "start_time": "2020-02-19T18:57:25.064308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of values for the max_depth hyperparameter\n",
    "max_depth_list = list(range(3,56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.089274Z",
     "start_time": "2020-02-19T18:57:25.075279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(criterion_list, max_feature_list, max_depth_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.104202Z",
     "start_time": "2020-02-19T18:57:25.091237Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Sample hyperparameter combinations for a random search\n",
    "combinations_random_chosen = random.sample(combinations_list, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.119171Z",
     "start_time": "2020-02-19T18:57:25.106198Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the result\n",
    "combinations_random_chosen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing a Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the search space of random search allows us to easily see the coverage of this technique and therefore allows us to see the effect of our sampling on the search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use several different samples of hyperparameter combinations and produce visualizations of the search space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.135118Z",
     "start_time": "2020-02-19T18:57:25.121157Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_hyperparameters(n_samples):\n",
    "    global combinations_random_chosen\n",
    "\n",
    "    if n_samples == len(combinations_list):\n",
    "        combinations_random_chosen = combinations_list\n",
    "        return\n",
    "\n",
    "    combinations_random_chosen = []\n",
    "    random_combinations_index = np.random.choice(range(0, len(combinations_list)), n_samples, replace=False)\n",
    "    combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.151104Z",
     "start_time": "2020-02-19T18:57:25.138133Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_search():\n",
    "    rand_y, rand_x = [x[0] for x in combinations_random_chosen], [x[1] for x in combinations_random_chosen]\n",
    "\n",
    "    # Plot all together\n",
    "    plt.clf() \n",
    "    plt.scatter(rand_y, rand_x, c=['blue']*len(combinations_random_chosen))\n",
    "    plt.gca().set(xlabel='learn_rate', ylabel='min_samples_leaf', title='Random Search Hyperparameters')\n",
    "    plt.gca().set_xlim([0.01, 1.5])\n",
    "    plt.gca().set_ylim([10, 29])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.166044Z",
     "start_time": "2020-02-19T18:57:25.154070Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of values for the learning_rate hyperparameter\n",
    "learn_rate_list = list(np.linspace(0.01,1.5,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.181995Z",
     "start_time": "2020-02-19T18:57:25.169028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of values for the min_samples_leaf hyperparameter\n",
    "min_samples_list = list(range(10,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.197021Z",
     "start_time": "2020-02-19T18:57:25.183989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combination list\n",
    "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:25.212910Z",
     "start_time": "2020-02-19T18:57:25.198950Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm how hyperparameter combinations & print\n",
    "number_combs = len(combinations_list)\n",
    "number_combs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:26.235744Z",
     "start_time": "2020-02-19T18:57:25.214905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample and visualise combinations\n",
    "for x in [250, 1500, 5000]:\n",
    "    sample_hyperparameters(x)\n",
    "    visualize_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the bigger our sample space of a random search the more it looks like a grid search? In a later example we will look closer at comparing these two methods side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RandomizedSeachCV Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like the `GridSearchCV` library from Scikit Learn, `RandomizedSearchCV` provides many useful features to assist with efficiently undertaking a random search. We're going to create a `RandomizedSearchCV` object, making the small adjustment needed from the `GridSearchCV` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired options are:\n",
    "\n",
    "* A default Gradient Boosting Classifier Estimator\n",
    "* 5-fold cross validation\n",
    "* Use accuracy to score the models\n",
    "* Use 4 cores for processing in parallel\n",
    "* Ensure you refit the best model and return training scores\n",
    "* Randomly sample 10 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter grid should be for `learning_rate` (150 values between 0.1 and 2) and `min_samples_leaf` (all values between 20 and 65)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:26.250704Z",
     "start_time": "2020-02-19T18:57:26.237740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'learning_rate': np.linspace(0.1, 2, 150), 'min_samples_leaf': list(range(20, 65))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:57:26.266685Z",
     "start_time": "2020-02-19T18:57:26.253695Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create a random search object\n",
    "random_GBM_class = RandomizedSearchCV(\n",
    "    estimator = GradientBoostingClassifier(random_state=42),\n",
    "    param_distributions = param_grid,\n",
    "    n_iter = 10,\n",
    "    scoring='accuracy', n_jobs=4, cv = 5, refit=True, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:58:53.916148Z",
     "start_time": "2020-02-19T18:57:26.268660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit to the training data\n",
    "random_GBM_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:58:53.931109Z",
     "start_time": "2020-02-19T18:58:53.918141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the values used for both hyperparameters\n",
    "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
    "print(random_GBM_class.cv_results_['param_min_samples_leaf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearchCV in Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice building a RandomizedSearchCV object using Scikit Learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The desired options are:\n",
    "\n",
    "* A RandomForestClassifier Estimator with default 80 estimators\n",
    "* 3-fold cross validation\n",
    "* Use AUC to score the models\n",
    "* Use 4 cores for processing in parallel\n",
    "* Ensure you refit the best model and return training scores\n",
    "* Randomly sample 5 models for processing efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter grid should be for `max_depth` (all values between and including 5 and 25) and `max_features` ('auto' and 'sqrt')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:58:53.946068Z",
     "start_time": "2020-02-19T18:58:53.935099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:58:53.961029Z",
     "start_time": "2020-02-19T18:58:53.948064Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a random search object\n",
    "random_rf_class = RandomizedSearchCV(\n",
    "    estimator = RandomForestClassifier(n_estimators=80, random_state=42),\n",
    "    param_distributions = param_grid, n_iter = 5,\n",
    "    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.407804Z",
     "start_time": "2020-02-19T18:58:53.963024Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit to the training data\n",
    "random_rf_class.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.423278Z",
     "start_time": "2020-02-19T18:59:07.409795Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print the values used for both hyperparameters\n",
    "print(random_rf_class.cv_results_['param_max_depth'])\n",
    "print(random_rf_class.cv_results_['param_max_features'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Grid and Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid and Random Search Side by Side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the search space of random and grid search together allows us to easily see the coverage that each technique has and therefore brings to life their specific advantages and disadvantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will sample hyperparameter combinations in a grid search way as well as a random search way, then plot these to see the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.439259Z",
     "start_time": "2020-02-19T18:59:07.426271Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample grid coordinates\n",
    "grid_combinations_chosen = combinations_list[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.471182Z",
     "start_time": "2020-02-19T18:59:07.442226Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print result\n",
    "grid_combinations_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.487147Z",
     "start_time": "2020-02-19T18:59:07.473176Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of sample indexes\n",
    "sample_indexes = list(range(0,len(combinations_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.502067Z",
     "start_time": "2020-02-19T18:59:07.490100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Randomly sample 300 indexes\n",
    "random_indexes = np.random.choice(sample_indexes, 300, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.517025Z",
     "start_time": "2020-02-19T18:59:07.504061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use indexes to create random sample\n",
    "random_combinations_chosen = [combinations_list[index] for index in random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.533009Z",
     "start_time": "2020-02-19T18:59:07.520033Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_search(grid_combinations_chosen, random_combinations_chosen):\n",
    "    grid_y, grid_x = [x[0] for x in grid_combinations_chosen], [x[1] for x in grid_combinations_chosen]\n",
    "    rand_y, rand_x = [x[0] for x in random_combinations_chosen], [x[1] for x in random_combinations_chosen]\n",
    "\n",
    "    # Plot all together\n",
    "    plt.scatter(grid_y + rand_y, grid_x + rand_x, c=['red']*300 + ['blue']*300)\n",
    "    plt.gca().set(xlabel='learn_rate', ylabel='min_samples_leaf', title='Grid and Random Search Hyperparameters')\n",
    "    plt.gca().set_xlim([0.01, 3.0])\n",
    "    plt.gca().set_ylim([5, 24])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-19T18:59:07.765429Z",
     "start_time": "2020-02-19T18:59:07.534980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call the function to produce the visualization\n",
    "visualize_search(grid_combinations_chosen, random_combinations_chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can really see how a grid search will cover a small area completely whilst random search will cover a much larger area but not completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Week 5 - Data Preprocessing and Hyperparameter Tuning](https://radu-enuca.gitbook.io/ml-challenge/preprocessing-and-tuning)**\n",
    "\n",
    "*Have questions or comments? Visit the ML Challenge Mattermost Channel.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
